

import pandas as pd
from sqlalchemy import create_engine, text
import os
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
DATABASE_URL = "postgresql+psycopg2://postgres:password@localhost:5432/linkedin_jobs"
PROJECT_ROOT = Path(__file__).parent  # –ö–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
RESULTS_DIR = PROJECT_ROOT / "results"  # üìä –ü–∞–ø–∫–∞ –¥–ª—è CSV
CHARTS_DIR = PROJECT_ROOT / "charts"    # üñºÔ∏è –ü–∞–ø–∫–∞ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
RESULTS_DIR.mkdir(exist_ok=True)
CHARTS_DIR.mkdir(exist_ok=True)

class LinkedInJobsAnalyzer:
    def __init__(self, database_url):
        self.engine = create_engine(database_url)
        self.setup_logging()
    
    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        print(f"üöÄ LinkedIn Jobs Analytics - CareerFlow Platform")
        print(f"üìÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—É—â–µ–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üíæ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î: {DATABASE_URL.split('@')[1].split('/')[0]}")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã CSV: {RESULTS_DIR.absolute()}")
        print(f"üñºÔ∏è  –ì—Ä–∞—Ñ–∏–∫–∏ PNG: {CHARTS_DIR.absolute()}")
        print("-" * 80)
    
    def safe_filename(self, name):
        """–°–æ–∑–¥–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞"""
        # –£–¥–∞–ª—è–µ–º –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
        safe_name = "".join(c for c in name if c.isalnum() or c in (' ', '-', '_')).rstrip()
        # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
        safe_name = safe_name.replace(' ', '_').replace(':', '').replace('/', '_')
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        return safe_name[:50]
    
    def execute_query(self, query_name, sql_query, save_to_csv=False):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç SQL-–∑–∞–ø—Ä–æ—Å –∏ –≤—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        try:
            print(f"\n{'='*80}")
            print(f"üìä –ó–ê–ü–†–û–°: {query_name}")
            print(f"{'='*80}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            df = pd.read_sql_query(text(sql_query), self.engine)
            
            # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
            print(f"üìà –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(df):,}")
            print(f"üìã –°—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}")
            if len(df) > 0:
                print(f"üî¢ –î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π: {df.iloc[:, -1].min()} - {df.iloc[:, -1].max()}")
            
            print("\nüìä –ü–ï–†–í–´–ï 5 –°–¢–†–û–ö:")
            print(df.head().to_string(index=False))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if save_to_csv and len(df) > 0:
                safe_name = self.safe_filename(query_name)
                filename = f"{safe_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                filepath = RESULTS_DIR / filename
                df.to_csv(filepath, index=False)
                print(f"üíæ CSV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filepath.relative_to(PROJECT_ROOT)}")
            
            # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
            if len(df) > 0:
                self.create_chart(df, query_name, save_to_csv)
            
            return df
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ '{query_name}': {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()
    
    def create_chart(self, df, query_name, save_to_csv):
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ charts/"""
        try:
            if len(df) == 0:
                print("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞")
                return
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è
            plt.style.use('default')
            sns.set_palette("husl")
            fig, ax = plt.subplots(figsize=(12, 8))
            
            safe_name = self.safe_filename(query_name)
            chart_title = f"–ê–Ω–∞–ª–∏–∑: {query_name}"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö
            if 'job_count' in df.columns or 'total_jobs' in df.columns:
                # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è —Å—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –¥–ª—è —Å—á–µ—Ç—á–∏–∫–æ–≤
                metric_col = next((col for col in ['job_count', 'total_jobs', 'unique_jobs'] if col in df.columns), None)
                if metric_col:
                    top_n = min(15, len(df))
                    y_pos = range(top_n)
                    values = df.head(top_n)[metric_col].values
                    
                    bars = ax.barh(y_pos, values, color=sns.color_palette("husl", top_n))
                    ax.set_yticks(y_pos)
                    ax.set_yticklabels(df.head(top_n).iloc[:, 0].astype(str), fontsize=10)
                    ax.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π', fontsize=12)
                    ax.set_title(chart_title, fontsize=14, fontweight='bold')
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –ø–æ–ª–æ—Å—ã
                    for i, (bar, v) in enumerate(zip(bars, values)):
                        ax.text(v + max(values)*0.01, bar.get_y() + bar.get_height()/2, 
                               f'{v:,}', ha='left', va='center', fontsize=9)
                    
                    ax.invert_yaxis()
            
            elif 'avg_salary' in df.columns or 'med_salary' in df.columns:
                # –°—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –¥–ª—è –∑–∞—Ä–ø–ª–∞—Ç
                salary_col = next((col for col in ['avg_salary', 'med_salary'] if col in df.columns), None)
                if salary_col:
                    top_n = min(12, len(df))
                    x_pos = range(top_n)
                    values = df.head(top_n)[salary_col].values
                    labels = df.head(top_n).iloc[:, 0].astype(str)
                    
                    bars = ax.bar(x_pos, values, color=sns.color_palette("viridis", top_n))
                    ax.set_xticks(x_pos)
                    ax.set_xticklabels(labels, rotation=45, ha='right', fontsize=9)
                    ax.set_ylabel('–°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ ($)', fontsize=12)
                    ax.set_title(chart_title, fontsize=14, fontweight='bold')
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
                    for i, (bar, v) in enumerate(zip(bars, values)):
                        ax.text(bar.get_x() + bar.get_width()/2, v + max(values)*0.02, 
                               f'${v:,.0f}', ha='center', va='bottom', fontsize=10)
            
            elif 'remote_pct' in df.columns or any('percentage' in col.lower() for col in df.columns):
                # –ö—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –¥–ª—è –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤
                pct_col = next((col for col in df.columns if 'pct' in col.lower() or 'percentage' in col.lower()), None)
                if pct_col and len(df) <= 10:
                    labels = df.iloc[:, 0].astype(str)[:8]  # –ú–∞–∫—Å–∏–º—É–º 8 —Å–µ–∫—Ç–æ—Ä–æ–≤
                    sizes = df[pct_col].head(8).values
                    colors = sns.color_palette("pastel", len(labels))
                    
                    wedges, texts, autotexts = ax.pie(sizes, labels=labels, autopct='%1.1f%%', 
                                                    colors=colors, startangle=90)
                    ax.set_title(chart_title, fontsize=14, fontweight='bold')
            
            elif len(df) > 1 and df.select_dtypes(include=[np.number]).shape[1] > 0:
                # –õ–∏–Ω–µ–π–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 0:
                    x_data = range(len(df))
                    y_data = df[numeric_cols[0]].values
                    
                    ax.plot(x_data, y_data, marker='o', linewidth=2, markersize=6)
                    ax.set_xticks(x_data[::max(1, len(df)//10)])
                    ax.set_xticklabels(df.iloc[::max(1, len(df)//10), 0].astype(str), 
                                     rotation=45, ha='right')
                    ax.set_ylabel(numeric_cols[0], fontsize=12)
                    ax.set_title(chart_title, fontsize=14, fontweight='bold')
                    ax.grid(True, alpha=0.3)
            
            else:
                print("‚ö†Ô∏è  –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
                plt.close(fig)
                return
            
            # –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è
            ax.grid(True, alpha=0.3, linestyle='--')
            plt.tight_layout()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            chart_filename = f"{safe_name}_{timestamp}.png"
            chart_path = CHARTS_DIR / chart_filename
            
            plt.savefig(chart_path, dpi=300, bbox_inches='tight', 
                       facecolor='white', edgecolor='none')
            print(f"üñºÔ∏è  PNG —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {chart_path.relative_to(PROJECT_ROOT)}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            if save_to_csv:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º CSV
                plt.show()
            
            plt.close(fig)
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è '{query_name}': {e}")
            plt.close('all')
    
    def run_full_analysis(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å 8 –∫–ª—é—á–µ–≤—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏"""
        print("\nüéØ –ù–ê–ß–ò–ù–ê–ï–ú –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –†–´–ù–ö–ê –¢–†–£–î–ê")
        print("=" * 80)
        
        # –ö–ª—é—á–µ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        key_queries = [
            {
                "name": "–¢–û–ü-10 –ù–ê–í–´–ö–û–í 2025",
                "sql": """
                SELECT 
                    s.skill_name as skill,
                    s.skill_abr,
                    COUNT(DISTINCT js.job_id)::INTEGER as job_count,
                    ROUND(AVG(j.applies * 1.0 / NULLIF(j.views, 0))::NUMERIC, 4) as apply_ratio
                FROM job_skills js
                JOIN skills s ON js.skill_id = s.skill_id
                JOIN jobs j ON js.job_id = j.job_id
                WHERE j.views > 0
                GROUP BY s.skill_id, s.skill_name, s.skill_abr
                ORDER BY job_count DESC
                LIMIT 10
                """,
                "save_csv": True
            },
            {
                "name": "–ó–ê–†–ü–õ–ê–¢–´ –ü–û –û–¢–†–ê–°–õ–Ø–ú",
                "sql": """
                SELECT 
                    i.industry_name as industry,
                    COUNT(DISTINCT ji.job_id) as job_count,
                    ROUND(AVG(sal.med_salary)::NUMERIC, 0) as avg_salary,
                    ROUND(MIN(sal.med_salary)::NUMERIC, 0) as min_salary,
                    ROUND(MAX(sal.med_salary)::NUMERIC, 0) as max_salary
                FROM job_industries ji
                JOIN industries i ON ji.industry_id = i.industry_id
                JOIN jobs j ON ji.job_id = j.job_id
                JOIN salaries sal ON j.job_id = sal.job_id
                WHERE sal.med_salary IS NOT NULL AND sal.med_salary > 0
                GROUP BY i.industry_id, i.industry_name
                HAVING COUNT(DISTINCT ji.job_id) > 10
                ORDER BY avg_salary DESC
                LIMIT 15
                """,
                "save_csv": True
            },
            {
                "name": "–¢–û–ü-20 –ê–ö–¢–ò–í–ù–´–• –ö–û–ú–ü–ê–ù–ò–ô",
                "sql": """
                SELECT 
                    c.name as company,
                    c.city,
                    c.country,
                    COUNT(j.job_id) as total_jobs,
                    ROUND(AVG(sal.med_salary)::NUMERIC, 0) as avg_salary,
                    SUM(j.applies) as total_applies,
                    ROUND(AVG(j.views)::NUMERIC, 0) as avg_views
                FROM companies c
                JOIN jobs j ON c.company_id = j.company_id
                LEFT JOIN salaries sal ON j.job_id = sal.job_id
                GROUP BY c.company_id, c.name, c.city, c.country
                HAVING COUNT(j.job_id) > 20
                ORDER BY total_jobs DESC
                LIMIT 20
                """,
                "save_csv": True
            },
            {
                "name": "–£–î–ê–õ–Å–ù–ù–ê–Ø –†–ê–ë–û–¢–ê –ü–û –û–¢–†–ê–°–õ–Ø–ú",
                "sql": """
                SELECT 
                    i.industry_name as industry,
                    COUNT(DISTINCT ji.job_id) as total_jobs,
                    COUNT(DISTINCT CASE WHEN j.remote_allowed = TRUE THEN ji.job_id END) as remote_jobs,
                    ROUND(100.0 * COUNT(DISTINCT CASE WHEN j.remote_allowed = TRUE THEN ji.job_id END) / 
                          NULLIF(COUNT(DISTINCT ji.job_id), 0)::NUMERIC, 1) as remote_percentage
                FROM job_industries ji
                JOIN industries i ON ji.industry_id = i.industry_id
                JOIN jobs j ON ji.job_id = j.job_id
                GROUP BY i.industry_id, i.industry_name
                HAVING COUNT(DISTINCT ji.job_id) > 50
                ORDER BY remote_percentage DESC
                LIMIT 15
                """,
                "save_csv": True
            },
            {
                "name": "–ó–ê–†–ü–õ–ê–¢–´ –ü–û –£–†–û–í–ù–Æ –û–ü–´–¢–ê",
                "sql": """
                SELECT 
                    j.formatted_experience_level as experience_level,
                    COUNT(j.job_id) as job_count,
                    ROUND(AVG(sal.med_salary)::NUMERIC, 0) as avg_salary,
                    ROUND(PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY sal.med_salary)::NUMERIC, 0) as q25_salary,
                    ROUND(PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY sal.med_salary)::NUMERIC, 0) as q75_salary
                FROM jobs j
                JOIN salaries sal ON j.job_id = sal.job_id
                WHERE j.formatted_experience_level IS NOT NULL
                  AND sal.med_salary IS NOT NULL 
                  AND sal.med_salary > 0
                GROUP BY j.formatted_experience_level
                ORDER BY 
                    CASE 
                        WHEN j.formatted_experience_level ILIKE '%internship%' THEN 1
                        WHEN j.formatted_experience_level ILIKE '%entry%' THEN 2
                        WHEN j.formatted_experience_level ILIKE '%associate%' THEN 3
                        WHEN j.formatted_experience_level ILIKE '%mid%' THEN 4
                        WHEN j.formatted_experience_level ILIKE '%senior%' THEN 5
                        ELSE 6 
                    END
                """,
                "save_csv": True
            },
            {
                "name": "–†–ï–ì–ò–û–ù–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–†–ü–õ–ê–¢",
                "sql": """
                SELECT 
                    CASE 
                        WHEN j.location ILIKE '%, %' THEN 
                            SUBSTRING(j.location, 1, POSITION(',' IN j.location) - 1)
                        ELSE j.location 
                    END as region,
                    COUNT(j.job_id) as job_count,
                    ROUND(AVG(sal.med_salary)::NUMERIC, 0) as avg_salary,
                    MIN(sal.med_salary)::INTEGER as min_salary,
                    MAX(sal.med_salary)::INTEGER as max_salary
                FROM jobs j
                JOIN salaries sal ON j.job_id = sal.job_id
                WHERE sal.med_salary IS NOT NULL AND sal.med_salary > 0
                GROUP BY region
                HAVING COUNT(j.job_id) > 30
                ORDER BY avg_salary DESC
                LIMIT 20
                """,
                "save_csv": True
            },
           
            {
                "name": "–≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–¨ –†–ï–ö–†–£–¢–ò–ù–ì–ê",
                "sql": """
                SELECT 
                    c.name as company_name,
                    COUNT(j.job_id) as total_jobs,
                    SUM(j.views) as total_views,
                    SUM(j.applies) as total_applies,
                    ROUND(AVG(j.applies * 1.0 / NULLIF(j.views, 0))::NUMERIC, 4) as apply_to_view_ratio,
                    ROUND(AVG(j.views)::NUMERIC, 0) as avg_views_per_job
                FROM companies c
                JOIN jobs j ON c.company_id = j.company_id
                WHERE j.views > 0 AND j.applies > 0
                GROUP BY c.company_id, c.name
                HAVING COUNT(j.job_id) > 10
                ORDER BY apply_to_view_ratio DESC
                LIMIT 15
                """,
                "save_csv": True
            }
        ]
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã
        results = {}
        successful_queries = 0
        
        for i, query in enumerate(key_queries, 1):
            print(f"\n‚è≥ –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∑–∞–ø—Ä–æ—Å {i}/{len(key_queries)}...")
            df = self.execute_query(query["name"], query["sql"], query["save_csv"])
            if len(df) > 0:
                results[query["name"]] = df
                successful_queries += 1
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.print_summary_stats(results, successful_queries)
        
        return results
    
    def print_summary_stats(self, results, successful_queries):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞"""
        print(f"\n{'='*80}")
        print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–ê–õ–ò–ó–ê")
        print(f"{'='*80}")
        
        try:
            # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ë–î
            stats = pd.read_sql_query("""
                SELECT 
                    (SELECT COUNT(*) FROM companies) as total_companies,
                    (SELECT COUNT(*) FROM jobs) as total_jobs,
                    (SELECT COUNT(*) FROM skills) as total_skills,
                    (SELECT COUNT(*) FROM industries) as total_industries,
                    (SELECT ROUND(AVG(med_salary)::NUMERIC, 0) FROM salaries WHERE med_salary > 0) as avg_salary_all
            """, self.engine).iloc[0]
            
            print(f"üè¢ –í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π: {stats['total_companies']:,}")
            print(f"üíº –í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π: {stats['total_jobs']:,}")
            print(f"üéØ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤: {stats['total_skills']:,}")
            print(f"üè≠ –û—Ç—Ä–∞—Å–ª–µ–π: {stats['total_industries']:,}")
            print(f"üí∞ –°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ –≤—Å–µ–º –≤–∞–∫–∞–Ω—Å–∏—è–º: ${stats['avg_salary_all']:,.0f}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–æ–≤
            csv_files = list(RESULTS_DIR.glob("*.csv"))
            png_files = list(CHARTS_DIR.glob("*.png"))
            print(f"\nüìÅ –°–æ–∑–¥–∞–Ω–æ —Ñ–∞–π–ª–æ–≤:")
            print(f"   üìä CSV –æ—Ç—á–µ—Ç–æ–≤: {len(csv_files)}")
            print(f"   üñºÔ∏è  PNG –≥—Ä–∞—Ñ–∏–∫–æ–≤: {len(png_files)}")
            
            # –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            print(f"\n‚≠ê –ö–õ–Æ–ß–ï–í–´–ï –ò–ù–°–ê–ô–¢–´:")
            if '–¢–û–ü-10 –ù–ê–í–´–ö–û–í 2025' in results and len(results['–¢–û–ü-10 –ù–ê–í–´–ö–û–í 2025']) > 0:
                top_skill_row = results['–¢–û–ü-10 –ù–ê–í–´–ö–û–í 2025'].iloc[0]
                print(f"   üéØ –°–∞–º—ã–π –≤–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–≤—ã–∫: '{top_skill_row['skill']}' ({top_skill_row['job_count']:,} –≤–∞–∫–∞–Ω—Å–∏–π)")
            
            if '–ó–ê–†–ü–õ–ê–¢–´ –ü–û –û–¢–†–ê–°–õ–Ø–ú' in results and len(results['–ó–ê–†–ü–õ–ê–¢–´ –ü–û –û–¢–†–ê–°–õ–Ø–ú']) > 0:
                top_salary_row = results['–ó–ê–†–ü–õ–ê–¢–´ –ü–û –û–¢–†–ê–°–õ–Ø–ú'].iloc[0]
                print(f"   üí∞ –í—ã—Å—à–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞: ${top_salary_row['avg_salary']:,.0f} –≤ '{top_salary_row['industry']}'")
            
            if '–¢–û–ü-20 –ê–ö–¢–ò–í–ù–´–• –ö–û–ú–ü–ê–ù–ò–ô' in results and len(results['–¢–û–ü-20 –ê–ö–¢–ò–í–ù–´–• –ö–û–ú–ü–ê–ù–ò–ô']) > 0:
                top_company_row = results['–¢–û–ü-20 –ê–ö–¢–ò–í–ù–´–• –ö–û–ú–ü–ê–ù–ò–ô'].iloc[0]
                print(f"   üè¢ –°–∞–º—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å: '{top_company_row['company']}' ({top_company_row['total_jobs']:,} –≤–∞–∫–∞–Ω—Å–∏–π)")
            
            print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {successful_queries}/{len(results)}")
            print(f"üìÇ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
            print(f"   üìä {RESULTS_DIR.relative_to(PROJECT_ROOT)}/ - CSV —Ñ–∞–π–ª—ã")
            print(f"   üñºÔ∏è  {CHARTS_DIR.relative_to(PROJECT_ROOT)}/ - PNG –≥—Ä–∞—Ñ–∏–∫–∏")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É: {e}")
    
    def test_connection(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            df = pd.read_sql_query("SELECT COUNT(*) as total_jobs FROM jobs", self.engine)
            total = df['total_jobs'].iloc[0]
            print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ! –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ–¥–µ—Ä–∂–∏—Ç {total:,} –≤–∞–∫–∞–Ω—Å–∏–π")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–ø–æ–∫
            print(f"üìÅ –ü–∞–ø–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
            print(f"   üìä CSV: {RESULTS_DIR.absolute()}")
            print(f"   üñºÔ∏è  PNG: {CHARTS_DIR.absolute()}")
            
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            return False
    
    def cleanup_old_files(self, days=7):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã (—Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π)"""
        from datetime import datetime, timedelta
        
        cutoff_date = datetime.now() - timedelta(days=days)
        deleted_csv = 0
        deleted_png = 0
        
        # –û—á–∏—Å—Ç–∫–∞ CSV
        for file in RESULTS_DIR.glob("*.csv"):
            if file.stat().st_mtime < cutoff_date.timestamp():
                try:
                    file.unlink()
                    deleted_csv += 1
                except:
                    pass
        
        # –û—á–∏—Å—Ç–∫–∞ PNG
        for file in CHARTS_DIR.glob("*.png"):
            if file.stat().st_mtime < cutoff_date.timestamp():
                try:
                    file.unlink()
                    deleted_png += 1
                except:
                    pass
        
        if deleted_csv + deleted_png > 0:
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {deleted_csv} CSV –∏ {deleted_png} PNG —Ñ–∞–π–ª–æ–≤ (—Å—Ç–∞—Ä—à–µ {days} –¥–Ω–µ–π)")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –∑–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    print("üèÅ CareerFlow Analytics - –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ —Ç—Ä—É–¥–∞ LinkedIn")
    print("=" * 80)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analyzer = LinkedInJobsAnalyzer(DATABASE_URL)
    
    # –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    if not analyzer.test_connection():
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:")
        print("   ‚Ä¢ PostgreSQL –∑–∞–ø—É—â–µ–Ω")
        print("   ‚Ä¢ –ë–∞–∑–∞ 'linkedin_jobs' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç") 
        print("   ‚Ä¢ –ü–∞—Ä–æ–ª—å '355812' –≤–µ—Ä–Ω—ã–π")
        return
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    # analyzer.cleanup_old_files(days=7)
    
    # –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    print("\n" + "="*80)
    print("üéØ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê (8 –∑–∞–ø—Ä–æ—Å–æ–≤)")
    print("="*80)
    
    try:
        results = analyzer.run_full_analysis()
        
        print(f"\nüéâ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û!")
        print(f"üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(results)}")
        print(f"\nüìÅ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–•–†–ê–ù–ï–ù–´:")
        print(f"   üìä CSV —Ñ–∞–π–ª—ã: {RESULTS_DIR}")
        print(f"   üñºÔ∏è  PNG –≥—Ä–∞—Ñ–∏–∫–∏: {CHARTS_DIR}")
        
        # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–∫—Ä—ã—Ç—å –ø–∞–ø–∫–∏
        if os.name == 'posix':  # macOS/Linux
            print(f"\nüí° –û—Ç–∫—Ä—ã—Ç—å –ø–∞–ø–∫–∏:")
            print(f"   open {RESULTS_DIR}")
            print(f"   open {CHARTS_DIR}")
        elif os.name == 'nt':  # Windows
            print(f"\nüí° –û—Ç–∫—Ä—ã—Ç—å –ø–∞–ø–∫–∏:")
            print(f"   explorer {RESULTS_DIR}")
            print(f"   explorer {CHARTS_DIR}")
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  –ê–Ω–∞–ª–∏–∑ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()